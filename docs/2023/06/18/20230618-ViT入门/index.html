<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yaanggny.github.io","root":"/blog/","images":"/blog/images","scheme":"Gemini","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/blog/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/blog/js/config.js"></script>

    <meta name="description" content="Transformer最早用于NLP领域中，视觉Transformer（Visual Transformer，ViT）出自Google的论文 An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, ICLR 2021，是基于Transformer 模型在视觉领域的开篇之作。本文主要介绍其网络结构和基本原">
<meta property="og:type" content="article">
<meta property="og:title" content="视觉Transformer (ViT)入门">
<meta property="og:url" content="https://yaanggny.github.io/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="yaanggny的笔记">
<meta property="og:description" content="Transformer最早用于NLP领域中，视觉Transformer（Visual Transformer，ViT）出自Google的论文 An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, ICLR 2021，是基于Transformer 模型在视觉领域的开篇之作。本文主要介绍其网络结构和基本原">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yaanggny.github.io/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/fig-9196c2790e8d4904676729642204938dd442d6fd7cf29c086ce34cff52240cfa.png">
<meta property="og:image" content="https://yaanggny.github.io/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/fig-e73614ca47e2dfdbfaeda952b1f47973a2e6e0113bce3e35fd556b362afe0e01.png">
<meta property="og:image" content="https://yaanggny.github.io/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/ViT.gif">
<meta property="article:published_time" content="2023-06-18T09:04:18.000Z">
<meta property="article:modified_time" content="2023-06-18T09:07:50.849Z">
<meta property="article:author" content="yaanggny">
<meta property="article:tag" content="DL">
<meta property="article:tag" content="CV">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yaanggny.github.io/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/fig-9196c2790e8d4904676729642204938dd442d6fd7cf29c086ce34cff52240cfa.png">


<link rel="canonical" href="https://yaanggny.github.io/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://yaanggny.github.io/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/","path":"2023/06/18/20230618-ViT入门/","title":"视觉Transformer (ViT)入门"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>视觉Transformer (ViT)入门 | yaanggny的笔记</title>
  








  <noscript>
    <link rel="stylesheet" href="/blog/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">yaanggny的笔记</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text"> 摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">2.</span> <span class="nav-text"> 模型结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fine-tuning%E5%92%8C%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%87"><span class="nav-number">3.</span> <span class="nav-text"> Fine-tuning和高分辨率</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">4.</span> <span class="nav-text"> 参考资料</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">yaanggny</p>
  <div class="site-description" itemprop="description">日常记录</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/blog/archives/">
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/blog/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/blog/tags/">
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yaanggny.github.io/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="yaanggny">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yaanggny的笔记">
      <meta itemprop="description" content="日常记录">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="视觉Transformer (ViT)入门 | yaanggny的笔记">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          视觉Transformer (ViT)入门
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-06-18 17:04:18 / 修改时间：17:07:50" itemprop="dateCreated datePublished" datetime="2023-06-18T17:04:18+08:00">2023-06-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>Transformer最早用于NLP领域中，视觉Transformer（Visual Transformer，ViT）出自Google的论文 <em><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.11929.pdf">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, ICLR 2021</a></em>，是基于Transformer 模型在视觉领域的开篇之作。本文主要介绍其网络结构和基本原理。</p>
<h2 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要</h2>
<p>虽然Transformer体系结构已经成为自然语言处理任务的事实标准，但其在计算机视觉中的应用仍然有限。在视觉中，注意力要么与卷积网络结合使用，要么用于替换卷积网络的某些组件，同时保持其整体结构。我们证明，这种对CNN的依赖是不必要的，并且<strong>直接应用于图像块序列的纯变换器（Transformer）可以在图像分类任务中表现得很好。</strong> 当在大量数据上进行预训练并转移到多个中小型图像识别基准任务（ImageNet、CIFAR-100、VTAB等）时，与最先进的卷积网络相比，视觉Transformer获得了优异的结果，同时需要更少的计算资源进行训练。</p>
<p>基于自注意力结构，Transformer已成为NLP领域的首选方法。由于其计算效率和可扩展性（scalability），使得可以训练更大规模的网络，随着模型和数据的规模增长，仍然没有饱和的迹象。</p>
<p>在计算机视觉中，卷积架构仍然占据主导地位。许多研究受NLP中的成功启发，尝试在CNN类结构结合自注意力机制，但是表现并不好。在大规模图像分类中，经典的ResNet类网络结构仍然是效果最好的。</p>
<p>受Transformer扩展到NLP领域的成功启发，我们使用了把标准Transformer仅做小改动后直接应用到图像，但是结果令人沮丧。我们把图像分块，并对块生成特征（线性embedding）后送入Transformer，图像块按照NLP中token那样使用。在图像分类任务中使用监督训练，在中等规模数据集如ImageNet上训练，但是模型结果明显不如ResNet类网络的结果。</p>
<p>和本文最相关的研究是 <em><strong>On the relationship between selfattention and convolutional layers. ICLR, 2020</strong></em>，其提取2x2大小的图块，并使用全自注意力，其只适合于小分辨率图像。</p>
<p>我们认为这种结果是意料之中的，<strong>因为Transformer缺乏CNN网络的归纳性偏好（the inductive biases），因此不能在训练数据不充足的情况下泛化好。</strong></p>
<p>但是在更大规模数据集（14M-300M图片）上训练后情况变得不同，此时可以胜过归纳偏好。<strong>当在充足的大规模数据集上训练，再迁移到小数据集上时，ViT获得极好的结果。</strong></p>
<h2 id="模型结构"><a class="markdownIt-Anchor" href="#模型结构"></a> 模型结构</h2>
<figure align="center"><img src="/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/fig-9196c2790e8d4904676729642204938dd442d6fd7cf29c086ce34cff52240cfa.png">
<figcaption>ViT结构</figcaption></figure>
<p>标准Transformer输入token的一维序列，对于2D图像，将图像划分为展平块的序列，即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>通道的图像<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi></mrow></msup></mrow><annotation encoding="application/x-tex">x\in \mathbb{R}^{H\times W\times C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span></span></span></span></span></span></span></span></span>变为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>p</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mo stretchy="false">(</mo><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">x_p\in \mathbb{R}^{N\times (P^2C)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8252079999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9869199999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9869199999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">×</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>。即原始图像的分辨率为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">H\times W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>，通道数为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>，分块大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>P</mi></mrow><annotation encoding="application/x-tex">P\times P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>，总块数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><mi>H</mi><mi>W</mi><mi mathvariant="normal">/</mi><msup><mi>P</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">N=HW/P^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord">/</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>。整个Transformer使用隐藏（latent）向量大小<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span>，因此我们用可训练的MLP线性投影来展平patch，把该投影的输出称为patch embeddings。如公式(1)所示：<br />
<img src="/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/fig-e73614ca47e2dfdbfaeda952b1f47973a2e6e0113bce3e35fd556b362afe0e01.png" alt="picture 4" /></p>
<p>其中LN：LayerNorm，MSA：Multihead self-attention。</p>
<p>在原有输入序列前加入一个可学习的特征 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi mathvariant="normal">c</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{\rm class}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">c</span><span class="mord mathrm mtight">l</span><span class="mord mathrm mtight">a</span><span class="mord mathrm mtight">s</span><span class="mord mathrm mtight">s</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，类似于BERT。（<em>为执行分类，使用标准方法即给序列添加一个额外的分类token</em>）</p>
<p>使用了标准的可学习的一维位置编码，因为没有发现2D位置编码带来显著的性能提升。</p>
<p><strong>归纳偏好</strong> 我们发现视觉Transformer比CNN有更少的视觉上的归纳偏好。CNN中，局部性、二维邻域结构和平移不变性（translation equivariance）被结合到每一层并遍及整个模型。但是ViT中，只有MLP层是局部和平移不变的，尽管自注意力层是全局的。二维邻域结构被使用得很少：在模型开始前将图像划分为图块时或者fune-tuning时调整位置编码以应对不同分辨率的图像。此外位置编码在初始化时未携带任何2D图块位置信息，所有空间关系都是从头学习得到的。</p>
<p><strong>混合结构</strong> 除了使用原始图像块，可以将CNN输出的特征作为模型输入，即patch embedding projection模块可以将CNN输出的特征图进行映射。</p>
<figure align="center"><img src="/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/ViT.gif">
<figcaption>动图展示ViT运算过程</figcaption></figure>
<h2 id="fine-tuning和高分辨率"><a class="markdownIt-Anchor" href="#fine-tuning和高分辨率"></a> Fine-tuning和高分辨率</h2>
<p>通常我们在大数据集上预训练ViT，然后在小的下游任务上微调。为此我们移除前期的预测模块，并连接一个零初始化的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">D\times K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>的前馈网络，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>是下游任务的类别数。</p>
<p>对于大分辨率图像，我们保持块大小相同，这导致更大的序列长度（即N的大小），ViT支持任意大小的序列长度（不考虑内存约束）。<strong>对于大分辨率图像，位置编码不再有效，此时我们对预训练的位置编码进行2D插值。</strong></p>
<h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2>
<ul>
<li>
<p>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.11929.pdf">pdf</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/d4bc4f540c62">Visual Transformer (ViT)模型结构以及原理解析 - 简书</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://theaisummer.com/vision-transformer/">How the Vision Transformer (ViT) works in 10 minutes: an image is worth 16x16 words | AI Summer</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline/notebook">Vision Transformer (ViT): Tutorial + Baseline | Kaggle</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://github.com/FrancescoSaverioZuppichini/ViT">FrancescoSaverioZuppichini/ViT: Implementing Vi(sion)T(transformer)</a></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/06a40338dc7c">Visual Transformer (ViT) 代码实现 PyTorch版本 - 简书</a></li>
</ul>
</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>yaanggny
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://yaanggny.github.io/blog/2023/06/18/20230618-ViT%E5%85%A5%E9%97%A8/" title="视觉Transformer (ViT)入门">https://yaanggny.github.io/blog/2023/06/18/20230618-ViT入门/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/blog/tags/DL/" rel="tag"># DL</a>
              <a href="/blog/tags/CV/" rel="tag"># CV</a>
              <a href="/blog/tags/Transformer/" rel="tag"># Transformer</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/blog/2023/06/17/20230617-Python%E5%B9%B6%E8%A1%8C%E5%8C%96-%E8%BF%9B%E7%A8%8B%E6%B1%A0/" rel="prev" title="Python并行化-进程池">
                  <i class="fa fa-chevron-left"></i> Python并行化-进程池
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/blog/2023/08/05/20230805-WSL%E8%BF%9E%E6%8E%A5Android%E6%89%8B%E6%9C%BA/" rel="next" title="WSL连接Android手机">
                  WSL连接Android手机 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yaanggny</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/blog/js/comments.js"></script><script src="/blog/js/utils.js"></script><script src="/blog/js/motion.js"></script><script src="/blog/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/blog/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.css" integrity="sha256-gMRN4/6qeELzO1wbFa8qQLU8kfuF2dnAPiUoI0ATjx8=" crossorigin="anonymous">
  <script class="next-config" data-name="katex" type="application/json">{"copy_tex_js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/contrib/copy-tex.min.js","integrity":"sha256-Us54+rSGDSTvIhKKUs4kygE2ipA0RXpWWh0/zLqw3bs="}}</script>
  <script src="/blog/js/third-party/math/katex.js"></script>



</body>
</html>
